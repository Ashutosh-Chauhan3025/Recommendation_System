{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "API_KEY = \"AIzaSyDSfj5jz_irGP35_08FUV0bg-_dXIZhnQw\" \n",
    "\n",
    "\n",
    "def fetch_youtube_videos(query, max_results=10):\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/search?part=snippet&q={query}&type=video&maxResults={max_results}&key={API_KEY}\"\n",
    "    response = requests.get(url).json()\n",
    "    \n",
    "    video_data = []\n",
    "    for item in response.get('items', []):\n",
    "        video_id = item['id']['videoId']\n",
    "        title = item['snippet']['title']\n",
    "        description = item['snippet']['description']\n",
    "        \n",
    "\n",
    "        video_details_url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={video_id}&key={API_KEY}\"\n",
    "        video_details = requests.get(video_details_url).json()\n",
    "        \n",
    "        tags = video_details['items'][0]['snippet'].get('tags', [])\n",
    "        category_id = video_details['items'][0]['snippet']['categoryId']\n",
    "        \n",
    "        video_data.append({\n",
    "            'Video_ID': video_id,\n",
    "            'Title': title,\n",
    "            'Description': description,\n",
    "            'Tags': ', '.join(tags),\n",
    "            'Category_ID': category_id\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(video_data)\n",
    "\n",
    "\n",
    "input1=input(\"Enter the title\")\n",
    "data = fetch_youtube_videos(input1, max_results=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "data['combined_features'] = data['Title'] + \" \" + data['Description'] + \" \" + data['Tags']\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['combined_features'])\n",
    "\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Video_ID                                              Title\n",
      "2  v6uOhb-i30A  Japan U-20 ðŸ¥¶ || Blue Lock Season 2 #bluelock #...\n",
      "6  yn2nTk2daVo  Isagi Unlocks a New Ability | BLUE LOCK 2nd Se...\n",
      "9  hTfnf4y-sgQ          BLUE LOCK 2nd Season | OFFICIAL TRAILER 2\n",
      "7  Xj4f0YYzWNY  Blue Lock Season 2 Episode 6 Explained in Hind...\n",
      "1  qT3fjHxst-Y  Project Blue Lock is Real | #shorts #anime #bl...\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(video_id, cosine_sim, data):\n",
    "    idx = data.index[data['Video_ID'] == video_id][0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i[0] for i in sim_scores[1:6]]  # Get top 5 recommendations\n",
    "    \n",
    "    return data.iloc[top_indices]\n",
    "\n",
    "# Example: Recommend videos similar to the first video in the dataset\n",
    "recommendations = get_recommendations(data.iloc[0]['Video_ID'], cosine_sim, data)\n",
    "print(recommendations[['Video_ID', 'Title']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended videos based on the title 'travelling':\n",
      "- Ep 1| Travelling through North East India | Off To Arunachal | The Journey Begins | Pasighat (JLZlCZ0)\n",
      "- Backpacking In Meghalaya | NorthEast India Trip | Sohra, Living Roots Bridge | Tanya Khanijow (n79Rv0F48)\n",
      "- Amazing NorthEast | Assam Meghalaya Arunachal | Complete Tour | Pradesh | Northeast India| TRAVEL (CdQjDOahkdY)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load User and YouTube datasets from JSON files\n",
    "user_data = pd.read_json(\"tableConvert.com_saro29.json\")  # Replace with your actual user dataset file\n",
    "youtube_data = pd.read_json(\"csvjson.json\")  # Replace with your actual YouTube dataset file\n",
    "\n",
    "# TF-IDF Vectorizer on user comments and YouTube descriptions\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Combine comments from user dataset and descriptions from YouTube dataset\n",
    "combined_text = user_data['Comments'].tolist() + youtube_data['description'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_text)\n",
    "\n",
    "# Split the TF-IDF matrix back into user and video parts\n",
    "user_tfidf = tfidf_matrix[:len(user_data)]\n",
    "video_tfidf = tfidf_matrix[len(user_data):]\n",
    "\n",
    "# Calculate cosine similarity between user preferences and video descriptions\n",
    "cosine_sim = cosine_similarity(user_tfidf, video_tfidf)\n",
    "\n",
    "# Function to recommend videos based on a given title\n",
    "def recommend_based_on_title(title, top_n=3):\n",
    "    # Find videos that match the title (case-insensitive search)\n",
    "    matching_videos = youtube_data[youtube_data['title'].str.contains(title, case=False, na=False)]\n",
    "    \n",
    "    if matching_videos.empty:\n",
    "        print(f\"No videos found with the title containing '{title}'\")\n",
    "        return\n",
    "    \n",
    "    # Get the index of the first matched video (in case there are multiple matches)\n",
    "    video_idx = matching_videos.index[0]\n",
    "\n",
    "    # Calculate cosine similarity between the chosen video and all other videos\n",
    "    sim_scores = cosine_similarity(video_tfidf[video_idx], video_tfidf)\n",
    "\n",
    "    # Get indices of top N most similar videos\n",
    "    top_video_indices = sim_scores.argsort()[0][-top_n:][::-1]\n",
    "\n",
    "    # Print recommended videos\n",
    "    print(f\"\\nRecommended videos based on the title '{title}':\")\n",
    "    for idx in top_video_indices:\n",
    "        video = youtube_data.iloc[idx]\n",
    "        print(f\"- {video['title']} ({video['link']})\")\n",
    "\n",
    "# Update recommendation logic for each user based on their past preferences (Liked Videos)\n",
    "def recommend_for_liked_videos():\n",
    "    recommended_videos = {}\n",
    "    for idx, row in user_data.iterrows():\n",
    "        if row['Liked'] == 'Yes':  # Ensure we're recommending only for users who liked the video\n",
    "            user_video_id = row['VideoID']\n",
    "            sim_scores = cosine_similarity(user_tfidf[idx], video_tfidf)\n",
    "\n",
    "            # Get indices of top 3 most similar videos\n",
    "            top_video_indices = sim_scores.argsort()[0][-3:][::-1]\n",
    "\n",
    "            # Store recommendations for liked videos\n",
    "            recommended_videos[user_video_id] = youtube_data.iloc[top_video_indices][['title', 'link']]\n",
    "\n",
    "    # Display the recommended videos only for users with liked videos\n",
    "    for user_video, videos in recommended_videos.items():\n",
    "        print(f\"\\nRecommended videos for User watching {user_video}:\")\n",
    "        for _, video in videos.iterrows():\n",
    "            print(f\"- {video['title']} ({video['link']})\")\n",
    "\n",
    "# Ask user for title-based recommendation input\n",
    "user_title = input(\"Enter a video title to get recommendations: \")\n",
    "recommend_based_on_title(user_title, top_n=3)\n",
    "\n",
    "# If you want to get recommendations for users, uncomment the following line:\n",
    "# recommend_for_liked_videos()  # Only call this function if you want to print user-based recommendations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
